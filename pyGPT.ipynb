{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:12:36.088877Z",
     "end_time": "2023-06-16T18:12:39.193326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nadav\\anaconda3\\envs\\pythonproject3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T19:13:16.312548Z",
     "end_time": "2023-06-16T19:13:19.144937Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a Generative Pretrained Autoencoder\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:14:11.938906Z",
     "end_time": "2023-06-16T18:14:11.955016Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "input_file, HTTP_reply = urllib.request.urlretrieve('https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt','input.txt')\n",
    "#print (HTTP_reply)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:22.465632Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Data\n",
    "after obtaining the text file, we will load the raw data and use it to create our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    raw_data = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:23.963370Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Playing With the Data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### trying a sample\n",
    "let's print the first 10 lines of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head = ''\n",
    "first_20_lines = raw_data.split('\\n')[:20]\n",
    "first_20_lines = [l+'\\n' for l in first_20_lines]\n",
    "head = head.join(first_20_lines)\n",
    "print(head)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:23.983521Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's find out what characters appear in the text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:23.991872Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_data)))\n",
    "print(''.join(chars))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:24.025124Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer\n",
    "first we will use a very simple character level encoding-decoding scheme. later on we will examine the differences and benefits of using a more sophisticated tokenizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "vocab_size = len(chars)\n",
    "stoi = {c:i for i, c in enumerate(chars)}\n",
    "itos = {i:c for i, c in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda t: ''.join([itos[i] for i in t])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:24.041371Z",
     "end_time": "2023-06-16T18:17:25.391121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets verify the encoder correctness condition: $$ D(x) = E^{-1}(x) \\rightarrow D(E(x)) = x $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdecode\u001B[49m(encode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mahoy\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'decode' is not defined"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"ahoy\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:24.055169Z",
     "end_time": "2023-06-16T18:17:25.399136Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### another tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:17:24.072002Z",
     "end_time": "2023-06-16T18:17:25.400156Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### encode the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mtensor(encode(raw_data))\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m (data[:\u001B[38;5;241m20\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(raw_data))\n",
    "print (data[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T15:59:52.241247Z",
     "end_time": "2023-06-16T15:59:52.613260Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separating to Train and Validation Sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "BLOCK_SIZE  = 40\n",
    "BATCH_SIZE = 5\n",
    "N_TRAIN = int(0.9*N)\n",
    "train = data[:N_TRAIN]\n",
    "val = data[N_TRAIN:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T15:59:54.042062Z",
     "end_time": "2023-06-16T15:59:54.062808Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_batch(dataset,batch_size = BATCH_SIZE):\n",
    "    n = len(dataset)\n",
    "    indices = torch.randint(n - BLOCK_SIZE, (batch_size,))\n",
    "    x = torch.stack([dataset[i : i + BLOCK_SIZE] for i in indices])\n",
    "    y = torch.stack([dataset[i+1 : i + BLOCK_SIZE +1 ]  for i in indices ])\n",
    "\n",
    "    return x,y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T17:37:18.036667Z",
     "end_time": "2023-06-16T17:37:18.125887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = get_batch(train)\n",
    "print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T17:37:18.053258Z",
     "end_time": "2023-06-16T17:37:18.180785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(batch[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T17:37:18.080849Z",
     "end_time": "2023-06-16T17:37:18.180785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = ''\n",
    "ys =batch[1].tolist()\n",
    "print(ys)\n",
    "# for i,s in enumerate(batch[0]):\n",
    "#     d = decode(s.tolist()+[ys[i]])\n",
    "#     print(f'{i}. {d}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T17:37:40.454586Z",
     "end_time": "2023-06-16T17:37:40.466704Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "seems legit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T17:37:41.595967Z",
     "end_time": "2023-06-16T17:37:41.611881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BigramNLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "\n",
    "        logits = self.token_embedding_table(x)\n",
    "\n",
    "        B, T, C = logits.size()\n",
    "        if targets is not None:\n",
    "            #pytorch cross entropy loss expects a 2d tensor of shape (B*T, C)\n",
    "            logits = logits.view(B*T,C)\n",
    "\n",
    "            # same for targets, we flatten it to a 1d tensor of shape (B*T)\n",
    "            targets = targets.view(B*T)\n",
    "            #cross entropy loss\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits, None\n",
    "\n",
    "    def generate(self, x, N):\n",
    "        print('hey')\n",
    "        \"\"\"\"\n",
    "        x is a 1d tensor of length T\n",
    "        n is the number of tokens to generate\n",
    "        returns a 1d tensor of length T+n\n",
    "        \"\"\"\n",
    "        T = x.size(0)\n",
    "        for i in range(N):\n",
    "            logits, _ = self.forward(x)\n",
    "            print(\"hey: \",logits)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat([x, next_token])\n",
    "            logits, _ = self.forward(x)\n",
    "            # we only care about the last token\n",
    "            logits = logits[-1]\n",
    "            #apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            #\n",
    "            next_x = torch.multinomial(probs, num_samples=1)\n",
    "            torch.cat((x, next_x), dim=0)\n",
    "            print(x)\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:04:21.948064Z",
     "end_time": "2023-06-16T18:04:22.012453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BigramNLM(vocab_size)\n",
    "\n",
    "logits, loss = model(batch[0], batch[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:04:24.532451Z",
     "end_time": "2023-06-16T18:04:24.564511Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## using adam optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:04:25.724688Z",
     "end_time": "2023-06-16T18:04:25.757138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for step in range(10):\n",
    "\n",
    "    #load data to train on\n",
    "    x, y = get_batch(train)\n",
    "\n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = model(batch[0], batch[1])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step: {step}, loss: {loss.item()}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:04:37.658340Z",
     "end_time": "2023-06-16T18:04:37.738684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generated = model.generate(batch[0], 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T18:09:49.895846Z",
     "end_time": "2023-06-16T18:09:49.928089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(generated)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
